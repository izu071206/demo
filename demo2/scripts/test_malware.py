"""
Script để test với malware samples
CẢNH BÁO: Chỉ chạy trong môi trường cách ly (sandbox/VM)
"""

import argparse
import sys
from pathlib import Path
import logging
import pickle

# Add src to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.features.static import OpcodeExtractor, CFGExtractor, APIExtractor
from src.features.feature_combiner import FeatureCombiner
from src.models import RandomForestModel, XGBoostModel, NeuralNetworkModel

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def extract_features_from_sample(file_path: str) -> dict:
    """
    Trích xuất features từ một sample
    
    Args:
        file_path: Path to sample file
        
    Returns:
        Dictionary of features
    """
    logger.info(f"Extracting features from {file_path}...")
    
    extractors = {
        'opcode': OpcodeExtractor(n_grams=[2, 3, 4]),
        'cfg': CFGExtractor(),
        'api': APIExtractor()
    }
    combiner = FeatureCombiner()
    
    all_features = {}
    
    # Opcode features
    try:
        with open(file_path, 'rb') as f:
            binary_data = f.read()
        opcode_features = extractors['opcode'].extract_features(binary_data, max_features=1000)
        all_features.update(opcode_features)
    except Exception as e:
        logger.warning(f"Error extracting opcodes: {e}")
    
    # CFG features
    try:
        cfg_features = extractors['cfg'].extract_features(file_path)
        all_features.update(cfg_features)
    except Exception as e:
        logger.warning(f"Error extracting CFG: {e}")
    
    # API features
    try:
        api_features = extractors['api'].extract_api_features(file_path, max_features=500)
        all_features.update(api_features)
    except Exception as e:
        logger.warning(f"Error extracting APIs: {e}")
    
    # Combine
    combined = combiner.combine(all_features)
    
    return {
        'features': combined,
        'feature_names': combiner.get_feature_names(),
        'raw_features': all_features
    }


def predict_with_model(model_path: str, model_type: str, features: dict) -> dict:
    """
    Dự đoán với model đã train
    
    Args:
        model_path: Path to trained model
        model_type: Type of model
        features: Extracted features
        
    Returns:
        Prediction results
    """
    logger.info(f"Loading {model_type} model from {model_path}...")
    
    # Load model
    if model_type == 'random_forest':
        model = RandomForestModel()
    elif model_type == 'xgboost':
        model = XGBoostModel()
    elif model_type == 'neural_network':
        model = NeuralNetworkModel()
    else:
        raise ValueError(f"Unknown model type: {model_type}")
    
    model.load(model_path)
    
    # Predict
    feature_vector = features['features'].reshape(1, -1)
    
    # Pad or truncate to match model input size
    # This is a simplified approach - in practice, you'd need to handle feature alignment
    prediction = model.predict(feature_vector)[0]
    probabilities = model.predict_proba(feature_vector)[0]
    
    return {
        'prediction': 'Obfuscated' if prediction == 1 else 'Benign',
        'confidence': float(max(probabilities)),
        'probabilities': {
            'benign': float(probabilities[0]),
            'obfuscated': float(probabilities[1])
        },
        'model_type': model_type
    }


def main():
    parser = argparse.ArgumentParser(
        description="Test malware sample với trained models",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
⚠️  CẢNH BÁO BẢO MẬT:
- Chỉ chạy script này trong môi trường cách ly (sandbox/VM)
- Không chạy trên hệ thống production
- Tuân thủ các quy định pháp lý về phân tích malware
        """
    )
    
    parser.add_argument('sample', type=str, help='Path to sample file to analyze')
    parser.add_argument('--model', type=str, required=True, help='Path to trained model')
    parser.add_argument('--model-type', type=str, required=True,
                       choices=['random_forest', 'xgboost', 'neural_network'],
                       help='Type of model')
    parser.add_argument('--output', type=str, help='Output file for results (JSON)')
    
    args = parser.parse_args()
    
    # Check if sample exists
    if not Path(args.sample).exists():
        logger.error(f"Sample file not found: {args.sample}")
        return
    
    # Extract features
    features = extract_features_from_sample(args.sample)
    
    if len(features['features']) == 0:
        logger.error("No features extracted!")
        return
    
    logger.info(f"Extracted {len(features['features'])} features")
    
    # Predict
    results = predict_with_model(args.model, args.model_type, features)
    
    # Print results
    print("\n" + "="*50)
    print("KẾT QUẢ PHÂN TÍCH")
    print("="*50)
    print(f"File: {args.sample}")
    print(f"Kết quả: {results['prediction']}")
    print(f"Độ tin cậy: {results['confidence']*100:.2f}%")
    print(f"Xác suất Benign: {results['probabilities']['benign']*100:.2f}%")
    print(f"Xác suất Obfuscated: {results['probabilities']['obfuscated']*100:.2f}%")
    print(f"Model: {results['model_type']}")
    print("="*50)
    
    # Save results if output specified
    if args.output:
        import json
        output_data = {
            'sample': args.sample,
            'results': results,
            'feature_count': len(features['features'])
        }
        with open(args.output, 'w') as f:
            json.dump(output_data, f, indent=2)
        logger.info(f"Results saved to {args.output}")


if __name__ == "__main__":
    main()

